{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 0: PDF to Plain Text Extraction\n",
    "\n",
    "This notebook extracts plain text from PDF files using [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/), a fast and lightweight Python binding for the MuPDF library.\n",
    "\n",
    "## Why PyMuPDF?\n",
    "- **Fast**: Written in C under the hood, significantly faster than pure-Python alternatives\n",
    "- **Reliable**: Handles scanned PDFs, multi-column layouts, embedded fonts, and complex formatting\n",
    "- **Lightweight**: No Java or external service dependencies (unlike Apache Tika)\n",
    "- **Well-maintained**: Active development with regular releases\n",
    "\n",
    "## Use Case\n",
    "If your source documents are PDFs (e.g. corporate filings, legal documents, reports), this notebook converts them to plain text files that can then be fed into the import pipeline in **Notebook 1**.\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.9+\n",
    "- PDF files to process (place them in a directory of your choice)\n",
    "\n",
    "### Expected Runtime\n",
    "- ~1-2 seconds per typical PDF page\n",
    "- A 100-page document takes roughly 10-20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymupdf tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Set the paths for your input PDFs and where you want the extracted text files written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "# CONFIGURATION — update these paths to match your environment\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "PDF_INPUT_DIR = Path(\"/Users/henryadamcollie/Documents/GitHub/enron_resolution_neo4j/pdfs/pdfs_pdfs\")          # directory containing your PDF files\n",
    "TEXT_OUTPUT_DIR = Path(\"/Users/henryadamcollie/Documents/GitHub/enron_resolution_neo4j/pdfs/pdfs_text\")    # directory where .txt files will be written\n",
    "\n",
    "# Set to True to also extract per-page files (one .txt per page)\n",
    "SPLIT_BY_PAGE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PDF Text Extractor\n",
    "\n",
    "The `extract_text_from_pdf` function opens a single PDF and returns its full plain-text content. PyMuPDF's `get_text()` method handles:\n",
    "- Multi-column layouts (reads in natural reading order)\n",
    "- Embedded fonts and Unicode characters\n",
    "- Headers, footers, and page numbers\n",
    "- Tables (as best-effort plain text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract all text from a PDF file and return as a single string.\"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    pages = []\n",
    "    for page in doc:\n",
    "        pages.append(page.get_text())\n",
    "    doc.close()\n",
    "    return \"\\n\\n\".join(pages)\n",
    "\n",
    "\n",
    "def extract_text_by_page(pdf_path: Path) -> list[str]:\n",
    "    \"\"\"Extract text from a PDF file, returning a list with one entry per page.\"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    pages = []\n",
    "    for page in doc:\n",
    "        pages.append(page.get_text())\n",
    "    doc.close()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Single-File Test\n",
    "\n",
    "Try extracting text from one PDF to verify everything works before processing a full directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first PDF in the input directory for a quick test\n",
    "pdf_files = sorted(PDF_INPUT_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF file(s) in {PDF_INPUT_DIR.resolve()}\")\n",
    "\n",
    "if pdf_files:\n",
    "    sample_pdf = pdf_files[0]\n",
    "    print(f\"\\nTesting with: {sample_pdf.name}\")\n",
    "    print(\"═\" * 60)\n",
    "\n",
    "    sample_text = extract_text_from_pdf(sample_pdf)\n",
    "    # Show a preview (first 2000 chars)\n",
    "    preview = sample_text[:2000]\n",
    "    print(preview)\n",
    "    if len(sample_text) > 2000:\n",
    "        print(f\"\\n... [{len(sample_text) - 2000:,} more characters]\")\n",
    "    print(f\"\\nTotal characters extracted: {len(sample_text):,}\")\n",
    "else:\n",
    "    print(f\"\\nNo PDF files found. Place your PDFs in: {PDF_INPUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing\n",
    "\n",
    "Process all PDFs in the input directory and write `.txt` files to the output directory. Each output file keeps the same name as its source PDF but with a `.txt` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_files = sorted(PDF_INPUT_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Processing {len(pdf_files)} PDF(s) → {TEXT_OUTPUT_DIR.resolve()}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Extracting text\"):\n",
    "    try:\n",
    "        if SPLIT_BY_PAGE:\n",
    "            pages = extract_text_by_page(pdf_path)\n",
    "            # Write per-page files: document_p1.txt, document_p2.txt, ...\n",
    "            for i, page_text in enumerate(pages, start=1):\n",
    "                out_path = TEXT_OUTPUT_DIR / f\"{pdf_path.stem}_p{i}.txt\"\n",
    "                out_path.write_text(page_text, encoding=\"utf-8\")\n",
    "            full_text = \"\\n\\n\".join(pages)\n",
    "            char_count = len(full_text)\n",
    "            page_count = len(pages)\n",
    "        else:\n",
    "            full_text = extract_text_from_pdf(pdf_path)\n",
    "            char_count = len(full_text)\n",
    "            doc = pymupdf.open(pdf_path)\n",
    "            page_count = len(doc)\n",
    "            doc.close()\n",
    "\n",
    "        # Always write the combined file\n",
    "        out_path = TEXT_OUTPUT_DIR / f\"{pdf_path.stem}.txt\"\n",
    "        out_path.write_text(full_text, encoding=\"utf-8\")\n",
    "\n",
    "        results.append({\n",
    "            \"file\": pdf_path.name,\n",
    "            \"pages\": page_count,\n",
    "            \"characters\": char_count,\n",
    "            \"status\": \"ok\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"file\": pdf_path.name,\n",
    "            \"pages\": 0,\n",
    "            \"characters\": 0,\n",
    "            \"status\": f\"error: {e}\"\n",
    "        })\n",
    "\n",
    "print(f\"\\nDone. {len(results)} file(s) processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"Total files:      {len(df)}\")\n",
    "    print(f\"Successful:       {(df['status'] == 'ok').sum()}\")\n",
    "    print(f\"Errors:           {(df['status'] != 'ok').sum()}\")\n",
    "    print(f\"Total pages:      {df['pages'].sum():,}\")\n",
    "    print(f\"Total characters: {df['characters'].sum():,}\")\n",
    "    print()\n",
    "    display(df)\n",
    "\n",
    "    # Show any errors\n",
    "    errors = df[df[\"status\"] != \"ok\"]\n",
    "    if not errors.empty:\n",
    "        print(\"\\n⚠ Files with errors:\")\n",
    "        for _, row in errors.iterrows():\n",
    "            print(f\"  {row['file']}: {row['status']}\")\n",
    "else:\n",
    "    print(\"No results — did you place PDF files in the input directory?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "The extracted `.txt` files are now ready for downstream processing:\n",
    "\n",
    "1. **Feed into Notebook 1** — if the PDFs contain email-like content, adapt the parser in Notebook 1 to read from the text output directory instead of `maildir/`\n",
    "2. **Direct Neo4j import** — load the text content as document nodes for full-text search and entity extraction\n",
    "3. **Entity extraction** — use spaCy NER or an LLM to pull out people, organizations, and other entities from the plain text\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Empty text output | The PDF may be image-based (scanned). Consider adding OCR with `pymupdf` + Tesseract. |\n",
    "| Garbled characters | The PDF may use a non-standard font encoding. Try `page.get_text(\"text\", sort=True)` for better ordering. |\n",
    "| Missing tables | For structured table extraction, consider `pdfplumber` as an alternative. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
